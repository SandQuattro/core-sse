debug = true

provider = "openai"

mode = "base"

jwt {
  issuer = "sse-demo-sso"
  audience = "sse-demo"
}

db {
  driver = "postgres"
  host = "localhost"
  port = "5432"
  user = "postgres"
  name = "sse_demo"
  ssl = "disable"
}

ld {
  proto = "tcp"
  host = "127.0.0.1"
  port = "6676"
  app = "sse-demo-core"
}

integration {
  active = "openai"
  openai {
    proto = "https"
    host = "api.openai.com"
    uri {
      models = "/v1/models"
      files = "/v1/files"
      assistants = "/v1/assistants/"
      threads = "/v1/threads"
      chat = "/v1/chat/completions"
    }
    token = ""
    assistant = ""
    model = "gpt-4-turbo-preview"
  }
  gigachat {
    proto = "https"
    host = "gigachat.devices.sberbank.ru"
    uri {
      chat = "/api/v1/chat/completions"
    }
    auth = ""
    rqID = ""
    model = ""
  }
  huggingface {
    proto = "https"
    host = "api-inference.huggingface.co"
    uri {
      models = "/models"
      chat = "/meta-llama/Llama-2-70b-chat-hf"
    }
    token = ""
    model = "Llama-2-70b-chat-hf"
  }
  storage {
    proto = "http"
    host = "127.0.0.1"
    port = ""
    url = "/storage/upload"
  }
}

trace {
  address = "trc.<domain>/trace"
}

redis {
  host = "127.0.0.1"
  port = 6379
}

upload.timeout=60